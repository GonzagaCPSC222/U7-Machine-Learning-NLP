{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   height(cm)  weight(kg) t-shirt size\n",
      "0         158          58            M\n",
      "1         163          61            M\n",
      "2         165          61            L\n",
      "3         168          66            L\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"shirts.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Machine Learning\n",
    "* Supervised machine learning: labeled data (i.e., the dataset has an attribute we are interested in predicting for unseen instances)\n",
    "    * The attribute we want to predict is called the *class* or the *target*\n",
    "    * If the class is categorical -> classification task\n",
    "    * If the class is numeric -> regression task\n",
    "    * Example algorithm: k nearest neighbors (kNN) classifier and regressor\n",
    "* Unsupervised machine learning: unlabeled data (i.e., the dataset does not have an attribute we are interested in predicting)\n",
    "    * E.g., clustering/grouping, associations, outliers/anomalies, trends, etc.\n",
    "    * Example algorithm: k means clustering\n",
    "\n",
    "## Supervised ML\n",
    "* We need to divide a dataset into *training* and *testing* sets\n",
    "    * We train/build an algorithm/model using a training set\n",
    "    * We evaluate the algorithm/model using a testing set\n",
    "    * The training and testing sets are *different*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Example w/Sci-kit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   height(cm)  weight(kg)\n",
      "0         158          58\n",
      "1         163          61\n",
      "2         165          61\n",
      "3         168          66\n",
      "0    M\n",
      "1    M\n",
      "2    L\n",
      "3    L\n",
      "Name: t-shirt size, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# notation/convention of sci-kit learn API\n",
    "# X: feature matrix (2D data structure)\n",
    "# rows are instances and columns are attributes/features\n",
    "# y: class column (1D data structure)\n",
    "# the attribute/feature we want to predict\n",
    "# AKA target array, target vector, labels, etc.\n",
    "# _train and _test are used to denote training and testing sets, respectively\n",
    "X_train = df.drop([\"t-shirt size\"], axis=\"columns\")\n",
    "y_train = df[\"t-shirt size\"]\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.   ]\n",
      " [0.5   0.375]\n",
      " [0.7   0.375]\n",
      " [1.    1.   ]]\n",
      "[[0.3   0.625]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sprint/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# let's scale our feature values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# typically combine fit() transform() calls fit_transform()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "print(X_train_scaled)\n",
    "X_test = [[161, 63]] #2D\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M']\n"
     ]
    }
   ],
   "source": [
    "# now for kNN!\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3, metric=\"euclidean\")\n",
    "# build/train\n",
    "knn_clf.fit(X_train_scaled, y_train)\n",
    "# predict\n",
    "y_predicted = knn_clf.predict(X_test_scaled)\n",
    "print(y_predicted)\n",
    "# challenge: can you print out the neighbor distances?\n",
    "# read the docs: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing Thoughts on kNN\n",
    "* Inefficient algorithm, but it is a great first algorithm because it is easy to understand and implement\n",
    "* What if you have features that are categorical?\n",
    "    * Encode the values as integers (0, 1, 2, ...)\n",
    "        * Sci-kit learn's [`LabelEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) can help you with this\n",
    "    * Use another distance function, or create your own\n",
    "* kNN is one of MANY supervised ML algorithms\n",
    "    * Decision trees\n",
    "    * Random forests\n",
    "    * Naive Bayes\n",
    "    * Support vector machines (SVMs)\n",
    "    * Neural networks\n",
    "    * etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    height(cm)  weight(kg)\n",
      "0          158          58\n",
      "1          158          59\n",
      "2          158          63\n",
      "3          160          59\n",
      "4          160          60\n",
      "5          163          60\n",
      "6          163          61\n",
      "7          160          64\n",
      "8          163          64\n",
      "9          165          61\n",
      "10         165          62\n",
      "11         165          65\n",
      "12         168          62\n",
      "13         168          63\n",
      "14         168          66\n",
      "15         170          63\n",
      "16         170          64\n",
      "17         170          68\n",
      "0     M\n",
      "1     M\n",
      "2     M\n",
      "3     M\n",
      "4     M\n",
      "5     M\n",
      "6     M\n",
      "7     L\n",
      "8     L\n",
      "9     L\n",
      "10    L\n",
      "11    L\n",
      "12    L\n",
      "13    L\n",
      "14    L\n",
      "15    L\n",
      "16    L\n",
      "17    L\n",
      "Name: t-shirt size, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"shirt_sizes_long.csv\")\n",
    "X = df.drop([\"t-shirt size\"], axis=\"columns\")\n",
    "y = df[\"t-shirt size\"]\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Evaluation\n",
    "* In our last demo, we had 1 instance in our \"test set\"\n",
    "    * If the classifier predicted the label correctly -> 100% accuracy\n",
    "    * If the classifier predicted the label incorrectly -> 0% accuracy\n",
    "* Notes\n",
    "    * We want a \"large\" test set to get a good sense of how well our algorithm learned and generalizes to unseen instances\n",
    "    * Accuracy doesn't tell the whole story... (more later)\n",
    "* We need to divide a dataset into training and test set\n",
    "    * A few ways to do this\n",
    "        * Holdout method (DA7)\n",
    "        * Cross validation\n",
    "\n",
    "### Holdout Method\n",
    "* \"hold out\" some instances for testing\n",
    "    * Train on the remaining instances\n",
    "* Typically use a standard \"split\" or percentage holdout\n",
    "    * 2:1 split: holdout 1/3 for testing, train on remaining 2/3\n",
    "    * 25% holdout: holdout 25% for testing, train on remaining 75%\n",
    "        * Sci-kit learn default for `train_test_split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    height(cm)  weight(kg)\n",
      "9          165          61\n",
      "17         170          68\n",
      "13         168          63\n",
      "5          163          60\n",
      "11         165          65\n",
      "2          158          63\n",
      "1          158          59\n",
      "8          163          64\n",
      "16         170          64\n",
      "3          160          59\n",
      "4          160          60\n",
      "15         170          63\n",
      "14         168          66\n",
      "9     L\n",
      "17    L\n",
      "13    L\n",
      "5     M\n",
      "11    L\n",
      "2     M\n",
      "1     M\n",
      "8     L\n",
      "16    L\n",
      "3     M\n",
      "4     M\n",
      "15    L\n",
      "14    L\n",
      "Name: t-shirt size, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# shuffles by default\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, stratify=y)\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    height(cm)  weight(kg)\n",
      "12         168          62\n",
      "6          163          61\n",
      "7          160          64\n",
      "0          158          58\n",
      "10         165          62\n",
      "12    L\n",
      "6     M\n",
      "7     L\n",
      "0     M\n",
      "10    L\n",
      "Name: t-shirt size, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L' 'L' 'M' 'M' 'L']\n",
      "accuracy: 0.6\n",
      "accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_predicted = knn_clf.predict(X_test)\n",
    "print(y_predicted)\n",
    "acc = accuracy_score(y_test, y_predicted)\n",
    "print(\"accuracy:\", acc)\n",
    "# GS: adding after class another way to get accuracy\n",
    "knn_clf.fit(X_train, y_train)\n",
    "acc = knn_clf.score(X_test, y_test)\n",
    "print(\"accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# can a decision tree do better?\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "# task: take it from here!\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_predicted = tree_clf.predict(X_test)\n",
    "tree_acc = accuracy_score(y_test, y_predicted)\n",
    "print(\"tree accuracy:\", tree_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k Fold Cross Validation (GS adding after class)\n",
    "* With cross validation, every instance is in the test set exactly one time\n",
    "* Basic algorithm: divide the dataset into \"folds\"\n",
    "    * For each fold\n",
    "        * Test on the fold\n",
    "        * Train on the remaining folds (folds - fold)\n",
    "* Accuracy is the total correctly predicted over all the folds divided by the total number of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "[0.75       0.5        1.         0.66666667 0.66666667] 0.7166666666666666\n",
      "0.7222222222222222\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "[0.5        0.5        1.         1.         0.66666667] 0.7333333333333333\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "# do 5 fold cross validation for both the knn and decision tree classifiers\n",
    "for clf in [knn_clf, tree_clf]:\n",
    "    print(type(clf))\n",
    "    accuracies = cross_val_score(clf, X, y, cv=5)\n",
    "    print(accuracies, np.mean(accuracies))\n",
    "    # better way to calculate accuracy\n",
    "    y_predicted = cross_val_predict(clf, X, y, cv=5)\n",
    "    acc = accuracy_score(y, y_predicted)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variants of cross validation\n",
    "* Stratified k fold validation: each fold has roughly the same distribution of class labels\n",
    "    * Default for sci-kit learns cross validation\n",
    "        * https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "        * https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html\n",
    "* LOOCV (leave one out cross validation) k = N\n",
    "    * Inefficient\n",
    "    * Good when you need all the training data you can get"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
