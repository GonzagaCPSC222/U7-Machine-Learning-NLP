{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 222](https://github.com/GonzagaCPSC222) Intro to Data Science\n",
    "[Gonzaga University](https://www.gonzaga.edu/)\n",
    "\n",
    "[Gina Sprint](http://cs.gonzaga.edu/faculty/sprint/)\n",
    "\n",
    "# Intro to Natural Language Processing\n",
    "What are our learning objectives for this lesson?\n",
    "* Gain an overview of the field of NLP\n",
    "* Install several Python libraries for natural language processing\n",
    "* Perform common text processing and analyses with the textblob module, including\n",
    "    * Parts of speech tagging\n",
    "    * Sentiment analysis\n",
    "    * Stemming and lemmatization\n",
    "    * Etc.\n",
    "\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* Intro to Python for Computer Science and Data Science by Deitel and Deitel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-up Task(s)\n",
    "* TBD\n",
    "\n",
    "## Today\n",
    "* Announcements\n",
    "    * Let's go over IQ9\n",
    "    * IQ10 (last one!!) on U7/DA7 (no NLP) TBD\n",
    "    * DA7 is due TBD. Questions?\n",
    "    * Mid project check-ins due TBD (Cleaning, EDA, and at least 1 hypothesis test)\n",
    "* Today\n",
    "    * Mid project check ins\n",
    "* Next class (last one!!): course evals, project stuff, confusion matrices, NLP Yelp API demo, closing thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install NLP Libraries\n",
    "* There are some NLP libraries we are going to use that don't come with Anaconda, so we will need to install them separately\n",
    "* Open Anaconda prompt and install the following modules:\n",
    "    * textblob\n",
    "        * `pip install textblob`\n",
    "        * `python -m textblob.download_corpora`\n",
    "    * wordcloud\n",
    "        * `pip install wordcloud`\n",
    "    * textatistic\n",
    "        * `pip install textatistic`\n",
    "    * spaCy\n",
    "        * `pip install spacy`\n",
    "        * `python -m spacy download en_core_web_sm`\n",
    "        \n",
    "Notes:\n",
    "* On Windows you may need to right click on Anaconda prompt in the start menu and choose \"More\" -> \"Run as administrator\"\n",
    "* On Mac M1, `spacy` will install but is not currently running on the arm architecture (for this reason I'll be using Google Colab or my older Intel-based Mac instead)\n",
    "* If pip cannot find the package you can try conda, e.g.: `conda install -c conda-forge spacy`\n",
    "\n",
    "## Intro to Natural Language Processing\n",
    "* Natural language processing (NLP) is the processing of a text collection (AKA corpus, or corpora for plural corpus), such as\n",
    "    * Tweets\n",
    "    * Facebook posts\n",
    "    * Conversations\n",
    "    * Product/service reviews\n",
    "    * Meeting logs\n",
    "    * Etc. \n",
    "* NLP is notoriously difficult because all of the above examples lack mathematical precision. A text's meaning can be influenced by context and perspective.\n",
    "* Thankfully, there are some really great Python NLP libraries with lots of built-in functionality and trained machine learning models we can use!!\n",
    "    * TextBlob\n",
    "    * WordCloud\n",
    "    * Textastatistic\n",
    "    * spaCy\n",
    "    * Gensim\n",
    "    * Google Cloud Natural Language API\n",
    "    * Microsoft Linguistic Analysis API\n",
    "    * etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic NLP Tasks w/TextBlob\n",
    "TextBlob is an OOP NLB text-processing library built on NLTK and pattern NLP libraries that simplifies many of the capabilities of these libraries, including but not limited to:\n",
    "1. Tokenization: splitting text into pieces called tokens, which are meaningful units, such as words and numbers\n",
    "1. Parts-of-speech tagging: identifying each word's part of speech, such as noun, verb, adjective, etc.\n",
    "1. Noun phrase extraction: locating groups of words that represent nouns, such as \"red brick factory\"\n",
    "1. Sentiment analysis: determining whether text has positive, neutral, or negative sentiment\n",
    "1. Inter-language translation and language detection: powered by [Google Translate](https://translate.google.com/)\n",
    "1. Inflection: pluralizing and singularizing words\n",
    "1. Spell checking and spelling correction\n",
    "1. Stemming: reducing words to their stems by removing prefixes or suffixes. For example, the stem of \"varieties\" is \"varieti\"\n",
    "1. Lemmatization: like stemming, but produces real words based on the original words' context. For example, the lemmatization of \"varieties\" is \"variety\"\n",
    "1. Word frequencies: determining how often each word appears in a corpus\n",
    "1. WordNet integration: WordNet is a database used to find word definitions, synonyms, and antonyms\n",
    "1. Stop word elimination: removing common words, such as \"a\", \"an\", \"the\", \"I\", \"we\", \"you\", and more to analyze the important words in a corpus\n",
    "1. n-grams: producing sets of consecutive words in a corpus for use in identifying words that frequently appear adjacent to one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"The Computer Science program at Gonzaga prepares students for careers and graduate study in the practice and science of computing.\"), Sentence(\"The program is built on a broad and rigorous foundation of science, mathematics, software engineering, and advanced computer science topics.\")]\n",
      "['The', 'Computer', 'Science', 'program', 'at', 'Gonzaga', 'prepares', 'students', 'for', 'careers', 'and', 'graduate', 'study', 'in', 'the', 'practice', 'and', 'science', 'of', 'computing', 'The', 'program', 'is', 'built', 'on', 'a', 'broad', 'and', 'rigorous', 'foundation', 'of', 'science', 'mathematics', 'software', 'engineering', 'and', 'advanced', 'computer', 'science', 'topics']\n"
     ]
    }
   ],
   "source": [
    "# grabbing text from https://www.gonzaga.edu/catalogs/current/undergraduate/school-of-engineering-and-applied-science/computer-science\n",
    "gu_cs_text = \"The Computer Science program at Gonzaga prepares students for careers and graduate study in the practice and science of computing. The program is built on a broad and rigorous foundation of science, mathematics, software engineering, and advanced computer science topics.\"\n",
    "blob = TextBlob(gu_cs_text)\n",
    "print(blob.sentences)\n",
    "print(blob.words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('Computer', 'NNP'), ('Science', 'NNP'), ('program', 'NN'), ('at', 'IN'), ('Gonzaga', 'NNP'), ('prepares', 'VBZ'), ('students', 'NNS'), ('for', 'IN'), ('careers', 'NNS'), ('and', 'CC'), ('graduate', 'NN'), ('study', 'NN'), ('in', 'IN'), ('the', 'DT'), ('practice', 'NN'), ('and', 'CC'), ('science', 'NN'), ('of', 'IN'), ('computing', 'VBG'), ('The', 'DT'), ('program', 'NN'), ('is', 'VBZ'), ('built', 'VBN'), ('on', 'IN'), ('a', 'DT'), ('broad', 'JJ'), ('and', 'CC'), ('rigorous', 'JJ'), ('foundation', 'NN'), ('of', 'IN'), ('science', 'NN'), ('mathematics', 'NNS'), ('software', 'NN'), ('engineering', 'NN'), ('and', 'CC'), ('advanced', 'VBD'), ('computer', 'NN'), ('science', 'NN'), ('topics', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "# POS tagging\n",
    "print(blob.tags)\n",
    "# tagset list with examples available here: https://medium.com/@gianpaul.r/tokenization-and-parts-of-speech-pos-tagging-in-pythons-nltk-library-2d30f70af13b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task\n",
    "# display parts of speech tags for \"My dog is cute\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['computer', 'science program', 'gonzaga', 'graduate study', 'rigorous foundation', 'software engineering', 'computer science topics']\n"
     ]
    }
   ],
   "source": [
    "# noun phrases\n",
    "print(blob.noun_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task\n",
    "# show the noun phrases for the sentence \"The red brick factory is for sale\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Computer Science program at Gonzaga prepares students for careers and graduate study in the practice and science of computing.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "\n",
      "The program is built on a broad and rigorous foundation of science, mathematics, software engineering, and advanced computer science topics.\n",
      "Sentiment(polarity=0.23125, subjectivity=0.45625)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sentiment analysis\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence)\n",
    "    print(sentence.sentiment)\n",
    "    print()\n",
    "# polarity indicates sentiment in [-1.0 (negative), 1.0 (positive)] 0.0 is neutral\n",
    "# subjectivity in [0.0 (objective), 1.0 (subjective)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task\n",
    "# show sentiment analysis for \"The food is not good\", \"The movie was not bad\", \"The movie was excellent!\"\n",
    "from textblob import Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-language Translation and Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language detection/translatiom with textblob is now deprecated:\n",
    "# https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=detect_language#textblob.blob.TextBlob.detect_language\n",
    "# Deprecated since version 0.16.0: Use the official Google Translate API instead.\n",
    "# link to learn more about Google Translate API: https://cloud.google.com/translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices\n",
      "fish\n",
      "cactus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WordList(['Thes', 'Computers', 'Sciences', 'programs', 'ats', 'Gonzagas', 'preparess', 'studentss', 'fors', 'careerss', 'ands', 'graduates', 'studies', 'ins', 'thes', 'practices', 'ands', 'sciences', 'ofs', 'computings', 'Thes', 'programs', 'iss', 'builts', 'ons', 'some', 'broads', 'ands', 'rigorouss', 'foundations', 'ofs', 'sciences', 'mathematics', 'software', 'engineerings', 'ands', 'advanceds', 'computers', 'sciences', 'topicss'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inflection\n",
    "# inflections are different forms of the same words, such as singular and plural\n",
    "# e.g. person and people\n",
    "# and different verb tenses\n",
    "# e.g. run and ran\n",
    "\n",
    "# often want to convert all inflected words into same form for more accurate word frequencies\n",
    "\n",
    "from textblob import Word\n",
    "\n",
    "index = Word(\"index\")\n",
    "print(index.pluralize())\n",
    "fish = Word(\"fish\")\n",
    "print(fish.pluralize())\n",
    "cacti = Word(\"cacti\")\n",
    "print(cacti.singularize())\n",
    "\n",
    "wordlist = blob.words\n",
    "wordlist.pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task\n",
    "# singularize \"children\" and pluralize \"focus\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell Checking and Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('they', 0.5713042216741622), ('their', 0.42869577832583783)]\n",
      "they\n",
      "The sentence has misspelled words.\n"
     ]
    }
   ],
   "source": [
    "# spell checking\n",
    "word = Word(\"theyr\")\n",
    "print(word.spellcheck())\n",
    "\n",
    "# spell correction\n",
    "print(word.correct()) # returns correctly spelled word that has the highest confidence\n",
    "print(TextBlob(\"Ths sentense has missplled wrds.\").correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task\n",
    "# correct the spelling in \"I canot beleive I misspeled thees werds\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "varieti\n"
     ]
    }
   ],
   "source": [
    "# normalization: preparing words for analysis\n",
    "# e.g. convert all words to lowercase, convert to word roots, etc.\n",
    "# e.g. \"program\", \"programs\", \"programmer\", \"programming\", \"programmed\", \"progammes\" -> \"program\"\n",
    "\n",
    "# stemming removes a prefix or suffix from a word leaving only a stem (which may or may not be a real word)\n",
    "word = Word(\"varieties\")\n",
    "print(word.stem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variety\n"
     ]
    }
   ],
   "source": [
    "# lemmatization is like stemming but factors in the word's part of speech and meaning thus resulting in a real word\n",
    "print(word.lemmatize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task\n",
    "# stem and lemmatize \"strawberries\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# word frequencies \n",
    "print(blob.word_counts[\"science\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions, Synonyms, and Antonyms w/WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enjoying or showing or marked by joy or pleasure', 'marked by good fortune', 'eagerly disposed to act or to be of service', 'well expressed and to the point']\n"
     ]
    }
   ],
   "source": [
    "# definitions\n",
    "# uses WordNet database from Princeton U\n",
    "# has word definitions, synonyms, and antonyms\n",
    "word = Word(\"happy\")\n",
    "print(word.definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('happy.a.01'), Synset('felicitous.s.02'), Synset('glad.s.02'), Synset('happy.s.04')]\n",
      "synonyms: {'happy', 'felicitous', 'glad', 'well-chosen'}\n"
     ]
    }
   ],
   "source": [
    "# synonyms\n",
    "print(word.synsets)\n",
    "# word.part of speech.index number of the corresponding meaning in the WordNet database\n",
    "\n",
    "synonyms = set()\n",
    "for synset in word.synsets:\n",
    "    for lemma in synset.lemmas():\n",
    "        synonyms.add(lemma.name())\n",
    "print(\"synonyms:\", synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antonyms: {'unhappy'}\n"
     ]
    }
   ],
   "source": [
    "# antonyms\n",
    "antonyms = set()\n",
    "for lemma in word.synsets[0].lemmas():\n",
    "    for antonym in lemma.antonyms():\n",
    "        antonyms.add(antonym.name())\n",
    "print(\"antonyms:\", antonyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['The', 'Computer', 'Science', 'program', 'at']),\n",
       " WordList(['Computer', 'Science', 'program', 'at', 'Gonzaga']),\n",
       " WordList(['Science', 'program', 'at', 'Gonzaga', 'prepares']),\n",
       " WordList(['program', 'at', 'Gonzaga', 'prepares', 'students']),\n",
       " WordList(['at', 'Gonzaga', 'prepares', 'students', 'for']),\n",
       " WordList(['Gonzaga', 'prepares', 'students', 'for', 'careers']),\n",
       " WordList(['prepares', 'students', 'for', 'careers', 'and']),\n",
       " WordList(['students', 'for', 'careers', 'and', 'graduate']),\n",
       " WordList(['for', 'careers', 'and', 'graduate', 'study']),\n",
       " WordList(['careers', 'and', 'graduate', 'study', 'in']),\n",
       " WordList(['and', 'graduate', 'study', 'in', 'the']),\n",
       " WordList(['graduate', 'study', 'in', 'the', 'practice']),\n",
       " WordList(['study', 'in', 'the', 'practice', 'and']),\n",
       " WordList(['in', 'the', 'practice', 'and', 'science']),\n",
       " WordList(['the', 'practice', 'and', 'science', 'of']),\n",
       " WordList(['practice', 'and', 'science', 'of', 'computing']),\n",
       " WordList(['and', 'science', 'of', 'computing', 'The']),\n",
       " WordList(['science', 'of', 'computing', 'The', 'program']),\n",
       " WordList(['of', 'computing', 'The', 'program', 'is']),\n",
       " WordList(['computing', 'The', 'program', 'is', 'built']),\n",
       " WordList(['The', 'program', 'is', 'built', 'on']),\n",
       " WordList(['program', 'is', 'built', 'on', 'a']),\n",
       " WordList(['is', 'built', 'on', 'a', 'broad']),\n",
       " WordList(['built', 'on', 'a', 'broad', 'and']),\n",
       " WordList(['on', 'a', 'broad', 'and', 'rigorous']),\n",
       " WordList(['a', 'broad', 'and', 'rigorous', 'foundation']),\n",
       " WordList(['broad', 'and', 'rigorous', 'foundation', 'of']),\n",
       " WordList(['and', 'rigorous', 'foundation', 'of', 'science']),\n",
       " WordList(['rigorous', 'foundation', 'of', 'science', 'mathematics']),\n",
       " WordList(['foundation', 'of', 'science', 'mathematics', 'software']),\n",
       " WordList(['of', 'science', 'mathematics', 'software', 'engineering']),\n",
       " WordList(['science', 'mathematics', 'software', 'engineering', 'and']),\n",
       " WordList(['mathematics', 'software', 'engineering', 'and', 'advanced']),\n",
       " WordList(['software', 'engineering', 'and', 'advanced', 'computer']),\n",
       " WordList(['engineering', 'and', 'advanced', 'computer', 'science']),\n",
       " WordList(['and', 'advanced', 'computer', 'science', 'topics'])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n-grams\n",
    "# an n-gram is a sequence of n text items, such as letters in words or words in a sentence\n",
    "# used to identify letters or words that frequently appear adjacent to one another\n",
    "# helpful for predicting the next letter or word the user will type\n",
    "# e.g. tab completion in an IDE or text suggestion in a messaging app\n",
    "blob.ngrams(5) # default is 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task\n",
    "# produce n-grams of 3 words for \"TextBlob is easy to use.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
